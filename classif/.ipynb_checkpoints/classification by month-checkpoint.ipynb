{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'creat_data_month' from 'comon' (../comon.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-a6661b9ac5c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcomon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreatMas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_ssp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreat_data_month\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplots_report\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'creat_data_month' from 'comon' (../comon.py)"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "import operator\n",
    "from xgboost import XGBClassifier\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from ksvd import ApproximateKSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from comon import creatMas, plot_ssp, creat_data_month\n",
    "from plots_report import plot_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean = 'BarentsSea'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['CZ1.txt', 'CZ2.txt', 'CZ3.txt', 'CZ4.txt','CZ5.txt', 'CZ6.txt',\n",
    "         'CZ7.txt','CZ8.txt','CZ9.txt','CZ10.txt', 'CZ11.txt','CZ12.txt']\n",
    "\n",
    "CZ = []\n",
    "for file in files:\n",
    "    with open('{0}/{1}'.format(ocean, file), 'r') as f:\n",
    "        line = f.readlines()\n",
    "        cz=creatMas(line)\n",
    "    CZ.append(cz)\n",
    "    \n",
    "_, N_cord = cz.shape\n",
    "\n",
    "with open('{}/zs.txt'.format(ocean), 'r') as f:\n",
    "    line = f.readlines()\n",
    "    line.remove(line[N_cord])\n",
    "zs = [-int(a) for a in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AEncoder(input_dim, latent_dim):\n",
    "    hidden_layer = int(input_dim * 0.8)\n",
    "    \n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    inp_layar1 = Dense(hidden_layer, activation='softplus',kernel_initializer='he_normal')(inputs)\n",
    "    #np_layar1 = Dropout(0.1)(inp_layar1)\n",
    "    \n",
    "    encoded = Dense(latent_dim, activation='softplus', kernel_initializer='he_normal')(inp_layar1)\n",
    "    \n",
    "    dec_lay = Dense(hidden_layer,activation='linear', kernel_initializer='he_normal')(encoded)\n",
    "    #dec_lay = Dropout(0.1)(dec_lay)\n",
    "    decoded = Dense(input_dim,activation='linear', kernel_initializer='he_normal')(dec_lay)\n",
    "    \n",
    "    autoencoder = Model(inputs, decoded)\n",
    "    encoder = Model(inputs, encoded)\n",
    "    \n",
    "    autoencoder = Model(inputs, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def researcher_pca(CLF,X_train, Y_train, X_test, Y_test, n_comp=[3,5,7,10]):\n",
    "    scores = []\n",
    "    for n in n_comp:\n",
    "        dec = PCA(n_components=n)\n",
    "        clf = CLF()\n",
    "        pipe = Pipeline([('dec', dec), ('clf', clf)])\n",
    "        pipe.fit(X_train, Y_train)\n",
    "        predict = pipe.predict(X_test)\n",
    "        score = accuracy_score(Y_test, predict)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "def researcher_ksvd(CLF, X_train, Y_train, X_test, Y_test, n_comp=[3,5,7,10]):\n",
    "    scores = []\n",
    "    for n in n_comp:\n",
    "        ksvd = ApproximateKSVD(n_components=n, transform_n_nonzero_coefs=n//2)\n",
    "        meantr = np.mean(X_train,axis=0)\n",
    "        dictionary = ksvd.fit(X_train - meantr).components_\n",
    "        gamma_train = ksvd.transform(X_train - meantr)\n",
    "        gamma_test = ksvd.transform(X_test - meantr)\n",
    "        \n",
    "        clf = CLF()\n",
    "        clf.fit(gamma_train, Y_train)\n",
    "        predict = clf.predict(gamma_test)\n",
    "        score = accuracy_score(Y_test, predict)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def researcher_ae(CLF, X_train, Y_train, X_test, Y_test, n_comp=[3,5,7,10]):\n",
    "    scores = []\n",
    "    scaler = StandardScaler()\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "    X_test_std = scaler.transform(X_test)\n",
    "    for n in n_comp:\n",
    "        autoencoder_std, encoder_std = AEncoder(N_cord, n)\n",
    "        autoencoder_std.fit(X_train_std, X_train_std,\n",
    "                epochs=750,\n",
    "                batch_size=64,\n",
    "                shuffle=True, verbose=0)\n",
    "          \n",
    "        test_embedding = encoder_std.predict(X_test_std)\n",
    "        train_embedding = encoder_std.predict(X_train_std)\n",
    "        \n",
    "        clf = CLF()\n",
    "        clf.fit(train_embedding, Y_train)\n",
    "        predict = clf.predict(test_embedding)\n",
    "        score = accuracy_score(Y_test, predict)\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes=['winter', 'summer'],\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_metrics(clf, X_train, X_test, y_train, y_test):\n",
    "    predict_train = clf.predict(X_train)\n",
    "    predict_test = clf.predict(X_test)\n",
    "    print('Accuracy на тренировочных данных: {}'.format(accuracy_score(y_train, predict_train)))\n",
    "    print('Accuracy на тестовых данных: {}'.format(accuracy_score(y_test, predict_test)))\n",
    "    \n",
    "    plot_confusion_matrix(confusion_matrix(y_train, predict_train), title='Confusion matrix для обучающих данных')\n",
    "    plot_confusion_matrix(confusion_matrix(y_test, predict_test), title='Confusion matrix для тестовых данных')\n",
    "    \n",
    "def feature_importances(clf, size = (10,12), title_x = 'Важность координаты', title_y = 'Глубина', zs = zs):\n",
    "    fi = clf.feature_importances_\n",
    "    x = range(1,len(fi)+1)\n",
    "    plt.figure(figsize=size)\n",
    "    plt.barh(x, fi)\n",
    "    plt.xlabel(title_x)\n",
    "    plt.ylabel(title_y)\n",
    "    plt.yticks(x,list(map(str,zs)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_data_month(CZ, N='all'):\n",
    "    X, Y = [], []\n",
    "    i = 0\n",
    "    for cz in CZ:\n",
    "        if N=='all':\n",
    "            N=len(cz)\n",
    "        X += list(cz)[:N]\n",
    "        Y += [i]*N\n",
    "        i += 1\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = creat_data_month(CZ)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, shuffle=True, test_size=0.2, stratify=Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8601190476190477"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[118,   8,   0,   6,   8,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  2, 115,   1,   0,  22,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 18,   2, 107,  13,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 41,   0,  25,  41,  16,   1,   0,   0,   0,   0,   0,  16],\n",
       "       [  2,   9,   0,   2, 119,   5,   0,   0,   0,   0,   3,   0],\n",
       "       [  0,   0,   4,   0,   0, 136,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1, 139,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 118,   4,   0,   0,   0],\n",
       "       [  1,   0,   0,   0,   0,   0,   0,   0, 139,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   1, 139,   0,   0],\n",
       "       [  2,   0,   0,   0,   0,   0,   0,   0,   0,   0, 137,   1],\n",
       "       [  1,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0, 137]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.84      0.73       140\n",
      "           1       0.86      0.82      0.84       140\n",
      "           2       0.77      0.76      0.77       140\n",
      "           3       0.66      0.29      0.41       140\n",
      "           4       0.72      0.85      0.78       140\n",
      "           5       0.95      0.97      0.96       140\n",
      "           6       0.89      0.99      0.94       140\n",
      "           7       1.00      0.84      0.91       140\n",
      "           8       0.97      0.99      0.98       140\n",
      "           9       1.00      0.99      1.00       140\n",
      "          10       0.98      0.98      0.98       140\n",
      "          11       0.89      0.98      0.93       140\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      1680\n",
      "   macro avg       0.86      0.86      0.85      1680\n",
      "weighted avg       0.86      0.86      0.85      1680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
